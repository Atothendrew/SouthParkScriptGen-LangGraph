# graph.py
"""
LangGraph workflow for South Park episode generation.
"""

import os
from datetime import datetime
from typing import Dict, List, TypedDict

from openai import OpenAI

from langgraph.graph import StateGraph, END
from langchain_core.tools import tool

# Load LMStudio endpoint from environment variable or default
LMSTUDIO_ENDPOINT = os.getenv("LMSTUDIO_ENDPOINT", "http://localhost:1234/v1")

@tool
def search_tool(query: str) -> str:
    """Searches the web for the given query."""
    # In a real application, you would integrate a web search API here.
    # For this example, we'll return a dummy response.
    return f"Search results for '{query}': South Park is an American animated sitcom created by Trey Parker and Matt Stone."

# Helper function to call LLM with a given prompt template
def llm_call(template: str, temperature: float = 0.7, tools: List = None, **kwargs) -> str:
    """Call LMStudio chat completion with the given template and kwargs."""
    prompt = template.format(**kwargs)
    client = OpenAI(base_url=LMSTUDIO_ENDPOINT, api_key="not-needed")
    
    messages = [{"role": "user", "content": prompt}]

    if tools:
        # In a real application, you would bind tools to the model
        # For this example, we'll just call the tool directly if the prompt indicates it
        if "tool_code" in prompt:
            # This is a very simplified tool calling mechanism for demonstration
            # In a real LangGraph agent, the LLM would output a tool_code action
            # and the agent executor would handle the tool invocation.
            tool_name = prompt.split("tool_code(")[1].split(")")[0]
            if tool_name == "search_tool":
                return search_tool(kwargs.get("query", ""))

    response = client.chat.completions.create(
        model="llama3.1",
        messages=messages,
        temperature=temperature,
    )
    return response.choices[0].message.content.strip()

# Import personas
from agents import PERSONAS, get_persona

# State definition
class EpisodeState(TypedDict):
    """
    State dictionary for the episode generation graph.
    Keys:
        prompt (str): The user-provided episode idea.
        agent_outputs (List[Dict]): List of dicts with keys 'name' and 'outline'.
        merged_outline (str): The combined outline after discussion.
        discussion_history (List[str]): A log of the conversation between the agents.
        act_one_script (str): The script for Act One.
        act_two_script (str): The script for Act Two.
        act_three_script (str): The script for Act Three.
        script (str): The final episode script.
        script_summary (str): A summary of the final episode script.
        log_dir (str): The directory to save the logs to.
        include_personas (List[str] | None): List of personas to include.
        exclude_personas (List[str] | None): List of personas to exclude.
    """
    prompt: str
    agent_outputs: List[Dict]
    merged_outline: str
    discussion_history: List[str]
    act_one_script: str
    act_two_script: str
    act_three_script: str
    script: str
    script_summary: str
    log_dir: str
    include_personas: List[str] | None
    exclude_personas: List[str] | None

# Agent brainstorming node
def brainstorm(state: EpisodeState) -> Dict:
    """Each agent generates an outline based on the episode prompt."""
    prompt = state["prompt"]
    outputs: List[Dict] = []
    brainstorm_dir = os.path.join(state["log_dir"], "brainstorm")
    os.makedirs(brainstorm_dir, exist_ok=True)

    for name, persona in PERSONAS.items():
        if name == "Deep Thought":
            continue
        if state["include_personas"] and name not in state["include_personas"]:
            continue
        if state["exclude_personas"] and name in state["exclude_personas"]:
            continue

        outline = llm_call(
            persona["brainstorm_prompt"], 
            temperature=persona["temperature"]["brainstorm"], 
            tools=[search_tool], 
            prompt=prompt
        )
        outputs.append({"name": name, "outline": outline})
        with open(os.path.join(brainstorm_dir, f"{name}.md"), "w", encoding="utf-8") as f:
            f.write(f"# {name}\n\n{outline}")

    state["agent_outputs"] = outputs
    state["discussion_history"] = []

    with open(os.path.join(state["log_dir"], "agent_outlines.md"), "w", encoding="utf-8") as f:
        f.write("# Agent Outlines\n\n")
        for item in outputs:
            f.write(f"### {item['name']}\n")
            f.write(f"{item['outline']}\n\n")

    return {"agent_outputs": outputs, "discussion_history": []}


# Agent feedback node
def agent_feedback(state: EpisodeState) -> Dict:
    """Each agent provides feedback on the other agents' ideas."""
    outlines_text = "\n\n".join(
        f"**{item['name']}**:\n{item['outline']}" for item in state["agent_outputs"]
    )
    feedback = []
    discussion_feedback_dir = os.path.join(state["log_dir"], "discussion_feedback")
    os.makedirs(discussion_feedback_dir, exist_ok=True)

    for name, persona in PERSONAS.items():
        if state["include_personas"] and name not in state["include_personas"]:
            continue
        if state["exclude_personas"] and name in state["exclude_personas"]:
            continue

        feedback_prompt = persona["discussion_prompt"]
        response = llm_call(
            feedback_prompt, 
            temperature=persona["temperature"]["discussion"], 
            tools=[search_tool], 
            outlines=outlines_text
        )
        feedback.append(f"**{name}'s Feedback:**\n{response}")
        with open(os.path.join(discussion_feedback_dir, f"{name}.md"), "w", encoding="utf-8") as f:
            f.write(f"# {name} Feedback\n\n{response}")

    state["discussion_history"] = feedback

    with open(os.path.join(state["log_dir"], "discussion_feedback.md"), "w", encoding="utf-8") as f:
        f.write("# Discussion Feedback\n\n")
        for item in feedback:
            f.write(f"{item}\n\n")

    return {"discussion_history": feedback}


# Merge outlines node
def merge_outlines(state: EpisodeState) -> Dict:
    """A neutral persona (Trey) merges outlines based on feedback."""
    outlines_text = "\n\n".join(
        f"**{item['name']}**:\n{item['outline']}" for item in state["agent_outputs"]
    )
    discussion_history = "\n\n".join(state["discussion_history"])
    
    # Use a neutral persona (Trey) to merge
    merge_prompt = PERSONAS["Trey Parker"]["discussion_prompt"]
    prompt = f"{merge_prompt}\n\nHere is the discussion history:\n{discussion_history}"
    merged_outline = llm_call(
        prompt, 
        temperature=PERSONAS["Trey Parker"]["temperature"]["discussion"], 
        tools=[search_tool], 
        outlines=outlines_text
    )
    state["merged_outline"] = merged_outline

    with open(os.path.join(state["log_dir"], "final_merged_outline.md"), "w", encoding="utf-8") as f:
        f.write(f"# Final Merged Outline\n\n{merged_outline}")

    return {"merged_outline": merged_outline}


# Refine outline node
def refine_outline(state: EpisodeState) -> Dict:
    """Each agent refines the merged outline."""
    merged_outline = state["merged_outline"]
    outputs: List[Dict] = []
    refine_dir = os.path.join(state["log_dir"], "refine")
    os.makedirs(refine_dir, exist_ok=True)

    for name, persona in PERSONAS.items():
        if name == "Deep Thought":
            continue
        if state["include_personas"] and name not in state["include_personas"]:
            continue
        if state["exclude_personas"] and name in state["exclude_personas"]:
            continue

        refined_outline = llm_call(
            persona["refine_prompt"], 
            temperature=persona["temperature"]["refine"], 
            tools=[search_tool], 
            outline=merged_outline
        )
        outputs.append({"name": name, "outline": refined_outline})
        with open(os.path.join(refine_dir, f"{name}.md"), "w", encoding="utf-8") as f:
            f.write(f"# {name}\n\n{refined_outline}")

    state["agent_outputs"] = outputs  # Overwrite agent_outputs with refined outlines for final discussion
    state["discussion_history"] = []  # Reset discussion history for final discussion

    return {"agent_outputs": outputs, "discussion_history": []}


# Final discussion node
def final_discussion(state: EpisodeState) -> Dict:
    """Agents have a final discussion and merge refined outlines."""
    outlines_text = "\n\n".join(
        f"**{item['name']}**:\n{item['outline']}" for item in state["agent_outputs"]
    )
    feedback = []
    final_discussion_feedback_dir = os.path.join(state["log_dir"], "final_discussion_feedback")
    os.makedirs(final_discussion_feedback_dir, exist_ok=True)

    for name, persona in PERSONAS.items():
        if state["include_personas"] and name not in state["include_personas"]:
            continue
        if state["exclude_personas"] and name in state["exclude_personas"]:
            continue

        feedback_prompt = persona["discussion_prompt"]
        response = llm_call(
            feedback_prompt, 
            temperature=persona["temperature"]["discussion"], 
            tools=[search_tool], 
            outlines=outlines_text
        )
        feedback.append(f"**{name}'s Final Feedback:**\n{response}")
        with open(os.path.join(final_discussion_feedback_dir, f"{name}.md"), "w", encoding="utf-8") as f:
            f.write(f"# {name} Final Feedback\n\n{response}")

    state["discussion_history"] = feedback  # Append to discussion history

    with open(os.path.join(state["log_dir"], "final_discussion_feedback.md"), "w", encoding="utf-8") as f:
        f.write("# Final Discussion Feedback\n\n")
        for item in feedback:
            f.write(f"{item}\n\n")

    # Use Trey Parker to merge the final outlines based on the final discussion
    merge_prompt = PERSONAS["Trey Parker"]["discussion_prompt"]
    final_merged_outline = llm_call(
        merge_prompt, 
        temperature=PERSONAS["Trey Parker"]["temperature"]["discussion"], 
        tools=[search_tool], 
        outlines=outlines_text, 
        discussion="\n\n".join(feedback)
    )
    state["merged_outline"] = final_merged_outline

    with open(os.path.join(state["log_dir"], "final_merged_outline.md"), "w", encoding="utf-8") as f:
        f.write(f"# Final Merged Outline\n\n{final_merged_outline}")

    return {"merged_outline": final_merged_outline}


# Write script nodes
def write_act_one(state: EpisodeState) -> Dict:
    """Writes the script for Act One."""
    act_one_prompt = (
        "You are a scriptwriter for South Park. Write Act One of a full episode script based on the following outline. "
        "Act One should introduce the characters and the main conflict. "
        "The script should be in the standard script format, with scene headings, character names, and dialogue. "
        "Make sure to include plenty of jokes and satire, in the style of South Park.\n\n---\n\n{outline}"
    )
    script = llm_call(
        act_one_prompt, 
        temperature=PERSONAS["Trey Parker"]["temperature"]["brainstorm"], 
        tools=[search_tool], 
        outline=state["merged_outline"]
    )
    state["act_one_script"] = script
    return {"act_one_script": script}

def write_act_two(state: EpisodeState) -> Dict:
    """Writes the script for Act Two."""
    act_two_prompt = (
        "You are a scriptwriter for South Park. Write Act Two of a full episode script based on the following outline. "
        "Act Two should develop the conflict and raise the stakes. "
        "The script should be in the standard script format, with scene headings, character names, and dialogue. "
        "Make sure to include plenty of jokes and satire, in the style of South Park.\n\n---\n\n{outline}"
    )
    script = llm_call(
        act_two_prompt, 
        temperature=PERSONAS["Trey Parker"]["temperature"]["brainstorm"], 
        tools=[search_tool], 
        outline=state["merged_outline"]
    )
    state["act_two_script"] = script
    return {"act_two_script": script}

def write_act_three(state: EpisodeState) -> Dict:
    """Writes the script for Act Three."""
    act_three_prompt = (
        "You are a scriptwriter for South Park. Write Act Three of a full episode script based on the following outline. "
        "Act Three should resolve the conflict and provide a satisfying conclusion. "
        "The script should be in the standard script format, with scene headings, character names, and dialogue. "
        "Make sure to include plenty of jokes and satire, in the style of South Park.\n\n---\n\n{outline}"
    )
    script = llm_call(
        act_three_prompt, 
        temperature=PERSONAS["Trey Parker"]["temperature"]["brainstorm"], 
        tools=[search_tool], 
        outline=state["merged_outline"]
    )
    state["act_three_script"] = script
    return {"act_three_script": script}


# Stitch script node
def stitch_script(state: EpisodeState) -> Dict:
    """Stitches the three acts together into a single script."""
    script = f"{state['act_one_script']}\n\n{state['act_two_script']}\n\n{state['act_three_script']}"
    state["script"] = script

    with open(os.path.join(state["log_dir"], "script.md"), "w", encoding="utf-8") as f:
        f.write(f"# Episode Script\n\n{script}")

    return {"script": script}


# Summarize script node
def summarize_script(state: EpisodeState) -> Dict:
    """Summarizes the final script."""
    summary_prompt = (
        "You are a scriptwriter for South Park. Summarize the following script in a few sentences. "
        "The summary should capture the main plot points and the overall tone of the episode.\n\n---\n\n{script}"
    )
    summary = llm_call(
        summary_prompt, 
        temperature=PERSONAS["Trey Parker"]["temperature"]["discussion"], 
        tools=[search_tool], 
        script=state["script"]
    )
    state["script_summary"] = summary
    return {"script_summary": summary}


# Build the graph
def build_graph() -> StateGraph:
    graph = StateGraph(EpisodeState)

    # Define nodes
    graph.add_node("brainstorm", brainstorm)
    graph.add_node("agent_feedback", agent_feedback)
    graph.add_node("merge_outlines", merge_outlines)
    graph.add_node("refine_outline", refine_outline)
    graph.add_node("final_discussion", final_discussion)
    graph.add_node("write_act_one", write_act_one)
    graph.add_node("write_act_two", write_act_two)
    graph.add_node("write_act_three", write_act_three)
    graph.add_node("stitch_script", stitch_script)
    graph.add_node("summarize_script", summarize_script)

    # Define edges
    graph.set_entry_point("brainstorm")
    graph.add_edge("brainstorm", "agent_feedback")
    graph.add_edge("agent_feedback", "merge_outlines")
    graph.add_edge("merge_outlines", "refine_outline")
    graph.add_edge("refine_outline", "final_discussion")
    graph.add_edge("final_discussion", "write_act_one")
    graph.add_edge("write_act_one", "write_act_two")
    graph.add_edge("write_act_two", "write_act_three")
    graph.add_edge("write_act_three", "stitch_script")
    graph.add_edge("stitch_script", "summarize_script")
    graph.add_edge("summarize_script", END)

    return graph